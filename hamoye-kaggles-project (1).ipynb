{"cells":[{"metadata":{"_uuid":"aa834368-e938-4497-b50b-6ec560b3653c","_cell_guid":"6cddcc0f-a35a-464d-aadc-6e4ea7d1ec31","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"810facd9-f3e2-43b0-b90b-7c51cd5d2a23","_cell_guid":"b2239166-1fc6-433b-9f98-9260b7f85aba","trusted":true},"cell_type":"code","source":"#Import necessary libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport gc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom sklearn.metrics import fbeta_score\nfrom tqdm import tqdm\nimport cv2\nfrom PIL import Image\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import optimizers\n\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import fbeta_score\nimport time\n%matplotlib inline\n\npal = sns.color_palette()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"45cff113-6456-4baf-b220-1ec10d6c60e1","_cell_guid":"9df3b41e-7e8a-4067-bf1d-b7508778d76c","trusted":true},"cell_type":"code","source":"#Load train and test CSVs\ndf_train = pd.read_csv('../input/planets-dataset/planet/planet/train_classes.csv')\ndf_test = pd.read_csv('../input/planets-dataset/planet/planet/sample_submission.csv')","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"fac6c564-6a10-4a0b-99fc-10e3d50f2b52","_cell_guid":"acc64565-1107-4c24-bb10-fdf3034fa524","trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"a2e1f809-354c-4fc1-afe4-1f69546e48c6","_cell_guid":"10e834fe-1c49-49ab-84c9-5802160e7570","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.metrics import plot_confusion_matrix\n# Since this is a multi lable task and the labels are given as tags in a single dataframe series\nbiner = MultiLabelBinarizer()\ntags = df_train['tags'].str.split()\ny = biner.fit_transform(tags)\n\nlabels = biner.classes_\nprint('Number of labels: ', len(labels))\nprint(labels)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"7592fbe3-fc40-4015-99c3-631e5f53d74c","_cell_guid":"6126a1d7-f826-48eb-827b-78500f164d96","trusted":true},"cell_type":"code","source":"from itertools import chain\ntag_list = list(chain.from_iterable([tags.split(\" \") for tags in df_train['tags'].values]))\ntag_set = set(tag_list)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"42658a7b-cdc4-483e-9f2f-5c54d1a277b3","_cell_guid":"939c8809-f14d-4d99-941f-73c67fa120d8","trusted":true},"cell_type":"code","source":"# Histogram of label instances\ntag_s = pd.Series(tag_list).value_counts() # To sort them by count\nfig, ax = plt.subplots(figsize=(16, 8))\nsns.barplot(x=tag_s, y=tag_s.index, orient='h')","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"4b7645e5-b205-4263-a616-e7f5c27645e9","_cell_guid":"d3a0d0e8-5ca0-49f5-ab94-66c39a20a096","trusted":true},"cell_type":"code","source":"#View some of the train images\nnew_style = {'grid': False}\nplt.rc('axes', **new_style)\n_, ax = plt.subplots(3, 3, sharex='col', sharey='row', figsize=(20, 20))\ni = 0\nfor f, l in df_train[:9].values:\n    img = cv2.imread('../input/planets-dataset/planet/planet/train-jpg/{}.jpg'.format(f))\n\n    ax[i // 3, i % 3].imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n    ax[i // 3, i % 3].set_title('{} - {}'.format(f, l))\n    #ax[i // 4, i % 4].show()\n    i += 1\n    \nplt.show()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"9f062f1b-a396-411c-8c7a-c86bbac3f8b0","_cell_guid":"ad1cb27c-b2f7-4d47-b9dc-521be4dab5a8","trusted":true},"cell_type":"code","source":"img_resize = (64, 64) # The resize size of each image ex: (64, 64) or None to use the default image size\nvalidation_split_size = 0.1","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"681b2287-f25c-47dc-a696-d3f295f67a19","_cell_guid":"8423df94-3dd2-481c-bf39-b8875763a24f","trusted":true},"cell_type":"code","source":"labels = df_train['tags'].apply(lambda x: x.split(' '))\nfrom collections import Counter, defaultdict\ncounts = defaultdict(int) #dictionary containing each individual label\nfor l in labels:\n    for l2 in l:\n        counts[l2] += 1\nt_list=list(counts.keys())","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"e704d176-53fa-4a80-a600-1f8f2dc9ce3c","_cell_guid":"55b81f27-2841-41ba-8741-bcce47832f5a","trusted":true},"cell_type":"code","source":"#Create a dictionary assigning a numerical value to each label\nlabel_map = {i:j for j, i in enumerate(t_list)}\nlabel_map","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"7410780f-5f9b-4996-9486-efa2086ae3bb","_cell_guid":"7de86a8e-db0e-43fa-8004-2db60a9316c4","trusted":true},"cell_type":"code","source":"labels_test = df_test['tags'].apply(lambda x: x.split(' '))\nfrom collections import Counter, defaultdict\ncounts_test = defaultdict(int)\nfor l in labels_test:\n    for l2 in l:\n        counts_test[l2] += 1\n\nt_list_test=list(counts_test.keys())\nlabel_map1 = {i:j for j, i in enumerate(t_list_test)}\nlabel_map1","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"dfa98e9b-7ae9-4c52-9e20-484026552e64","_cell_guid":"3aa8682b-8a89-45dd-9095-eedb25b67725","trusted":true},"cell_type":"code","source":"# One hot encode the training labels. Convert the images into pixels and resize them\nX_train, Y_train = [], []\nfor img, label in tqdm(df_train.values, miniters = 1000):\n  target = np.zeros(17)\n  for tag in label.split(' '):\n    target[label_map[tag]]=1\n  X_train.append(cv2.resize(cv2.imread('../input/planets-dataset/planet/planet/train-jpg/{}.jpg'.format(img)),(64,64)))\n  Y_train.append(target)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"001cdc24-7dc2-4ee9-b7c4-b6b64aafd470","_cell_guid":"d10263c9-337e-41fc-a75f-34b3c75a3314","trusted":true},"cell_type":"code","source":"#Change lists to numpy arrays and normalize\nx_train = np.array(X_train, np.float16)/255\ny_train = np.array(Y_train, np.uint8)\n#x_test = np.array(X_test, np.float16)/255\n\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, shuffle = True, random_state = 1)\n\nprint(x_train.shape, y_train.shape, x_val.shape, y_val.shape)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"d97dfa20-e04a-46db-8edd-a10814d0aaa8","_cell_guid":"c7f60386-8e02-4070-89c2-d8acc0108c2b","trusted":true},"cell_type":"code","source":"#convert the test images to pixels and resize them as well\nX_test=[]\nfor img, label in tqdm(df_test[:40669].values, miniters = 1000):\n  X_test.append(cv2.resize(cv2.imread('../input/planets-dataset/planet/planet/test-jpg/{}.jpg'.format(img)), (64,64)))\nfor img, label in tqdm(df_test[40669:].values, miniters = 1000):\n  X_test.append(cv2.resize(cv2.imread('../input/planets-dataset/test-jpg-additional/test-jpg-additional/{}.jpg'.format(img)), (64,64)))","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"f797b75d-80f9-46b2-9f80-06af51be8aaa","_cell_guid":"42e17c02-9f8f-4a02-986c-54423bd8dcf1","trusted":true},"cell_type":"code","source":"import sys\nsys.getsizeof(X_train)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"89f2b6e7-9b8d-4d18-8775-9b42a662b88e","_cell_guid":"51c1997b-9af7-4bef-a800-c18b6d2d9d4d","trusted":true},"cell_type":"code","source":"def Amazon_Model(input_shape,weight_path):\n    model = Sequential()\n    model.add(BatchNormalization(input_shape=input_shape))\n        \n    model.add(Conv2D(32, kernel_size=(3, 3),padding='same', activation='relu'))\n    model.add(Conv2D(32, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(64, kernel_size=(3, 3),padding='same', activation='relu'))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n        \n    model.add(Conv2D(128, kernel_size=(3, 3),padding='same', activation='relu'))\n    model.add(Conv2D(128, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n        \n    model.add(Conv2D(256, kernel_size=(3, 3),padding='same', activation='relu'))\n    model.add(Conv2D(256, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n        \n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(17, activation='sigmoid'))\n    if(weight_path!=None):\n        if os.path.isfile(weight_path):\n            model.load_weights(weight_path)\n    return model","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"947b0c9a-ecf0-454f-ac4b-797ad066bc51","_cell_guid":"da23dc60-60c5-4251-93a2-875673b5f4dd","trusted":true},"cell_type":"code","source":"model = Amazon_Model((64, 64,3),None)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"ab6407a4-26d8-493a-a844-94380fff347e","_cell_guid":"d5f888ff-0887-456e-8ab2-b75ddcd5df3c","trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy,metrics=['accuracy'])\ncallbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0)]\nhistory = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=20, batch_size=128,callbacks=callbacks,shuffle=True)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"622d3893-be2f-4384-92ac-c5b07cdf6b11","_cell_guid":"7427afb7-1573-409f-b466-03c0705f640b","trusted":true},"cell_type":"code","source":"ynew_test = []\nynew_train = []","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"02285fc1-3e43-4d12-bda7-822a6313404d","_cell_guid":"dcece92b-e5c4-42fa-8857-f6e6f0cb98e4","trusted":true},"cell_type":"code","source":"x_test = np.array(X_test, np.float16)/255","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"0a8debd5-cc5e-4842-80d6-3d2e5a0ca89a","_cell_guid":"e56e8124-a20f-447c-9a32-bfda1de36800","trusted":true},"cell_type":"code","source":"p_test = model.predict(x_test, batch_size = 128) #save the test predictions\nynew_test.append(p_test)\n\nresult = np.array(ynew_test[0])\nresult = pd.DataFrame(result, columns = labels)\nresult","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"31e3ab7c-17ec-4ffd-88ff-2344764fd450","_cell_guid":"2cbca8a3-c111-447a-b606-f51a1ae6badc","trusted":true},"cell_type":"code","source":"result['id'] = df_test['id']\nresult.to_csv(\"submission.csv\", index=False)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"4a0fecbc-1427-4bc6-bf9a-6977998f7c1c","_cell_guid":"4cd71be8-00e5-4a39-b526-bf92f0a62a21","trusted":true},"cell_type":"code","source":"","execution_count":0,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}